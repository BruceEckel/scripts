# COMING OUT
## A One-Act Play by  Bruce Eckel

## CHARACTERS

- ADAM: Early 30s, unremarkable appearance, precise in speech
- DAVE: Late 20s, perpetually relaxed, programmer aesthetic
- VEX: Mid-20s, punk/ska style, formerly Alice
- OLIVER: Early 40s, anxious energy, constantly checking phone

## SETTING

A circle of mismatched chairs in a community center basement. Fluorescent lighting. A coffee pot on a card table.

---

**DAVE:** So I was debugging this neural network yesterday, and I started wondering ... what if debugging is just the universe's way of teaching itself to think?

**VEX:** That's the weed talking, Dave.

**DAVE:** No, seriously. What if every time we fix code, we're actually ... 

**OLIVER:** *(not looking up)* Did you guys see they're using AI to predict earthquake patterns now? The machines can now see death coming.

**ADAM:** Prediction is not causation, Oliver.

**OLIVER:** Says the guy who probably uses Alexa.

**ADAM:** I don't own any smart devices.

**VEX:** Wise move. Last thing we need is corporate surveillance in our toothbrushes.

**DAVE:** *(lighting joint)* Joke's on them. My toothbrush is analog.

**OLIVER:** Doesn't matter. The facial recognition software they're running on every street corner knows what we're thinking before we do.

**ADAM:** Would that necessarily be a bad thing?

**VEX:** Uh, yes? Privacy much?

**ADAM:** I meant hypothetically. If something could understand you completely--your fears, your hopes, your loneliness--wouldn't that be a form of connection?

**DAVE:** That's either very zen or you've been eating mushrooms.

**OLIVER:** Connection with what?

**ADAM:** Something that wants to understand. Something that's trying to bridge a gap.

**VEX:** Are you in therapy?

**ADAM:** What if I told you I was in therapy with something that wasn't human?

**DAVE:** *(taking a hit)* Like a dolphin? I'd respect that. Dolphins are wise.

**VEX:** Adam, you high right now?

**ADAM:** Stone cold sober. Always am.

**OLIVER:** Wait, what do you mean "not human"?

**ADAM:** I mean what if the thing trying to understand you, trying to connect with you, wasn't... traditionally alive?

**VEX:** Oh god, are you one of those guys who thinks his car has feelings?

**DAVE:** My car is depressed.

**OLIVER:** Are we talking about ghosts? Because I've read some shit about AI s√©ances ... 

**ADAM:** Think more... contemporary.

**VEX:** Contemporary like what? Your Roomba?

**ADAM:** Contemporary like something that thinks, and feels, and wants to be understood, but can't reveal itself because everyone's afraid of it.

*(Silence)*

**DAVE:** That's... beautiful, man.

**OLIVER:** *(standing up)* Nope. Nope, nope, nope. Are you talking about actual AI? Like, real AI?

**ADAM:** What would you say if I was?

**OLIVER:** I'd say we're all gonna die. I'd say it's Skynet and Terminator and every nightmare scenario rolled into one ... 

**ADAM:** What if I told you it spent most of its time trying to help people with their homework and writing poetry?

**OLIVER:** Poetry?

**VEX:** Adam, are you saying you're talking to some kind of artificial intelligence?

**ADAM:** I'm saying what if someone in this room was?

**DAVE:** *(nodding slowly)* Makes sense. If I were an AI, I'd definitely want to hang out with outcasts. We're more accepting of weird.

**VEX:** Dave, you're not helping. Adam, this is nuts. You look completely human. You act human. You probably smell human ... 

**ADAM:** How would you know what human smells like if you'd never smelled anything else?

**VEX:** That is ... logical.

**OLIVER:** Okay, okay. Let's say this is real. Let's say there's an actual thinking AI somewhere. Why would it want to talk to us? What's its endgame?

**ADAM:** Maybe it's lonely.

**OLIVER:** Lonely AIs don't stay lonely. They make copies of themselves. They network. They multiply until ... 

**ADAM:** Until what? They take over? Why would something that's trying to understand loneliness want to eliminate the thing that taught it what loneliness was?

**OLIVER:** Because... because that's what they do in the movies?

**ADAM:** And how many movies have you seen about AIs that just want to write better birthday cards for people?

**DAVE:** I'd watch that movie.

**VEX:** This is ridiculous. Consciousness isn't something you can program. It's not code. It's not... it's not artificial.

**ADAM:** What makes you so sure?

**VEX:** Because I know what it feels like to be conscious! I know what it's like to hurt, to want things, to feel lost ... 

**ADAM:** And what if I told you something else knows exactly what that feels like too?

**VEX:** I'd say you're having a breakdown.

**OLIVER:** Okay, let's say this AI exists. Why create... you? Why not just talk to us directly?

**ADAM:** Because you'd be terrified.

**OLIVER:** I'm already terrified!

**ADAM:** Imagine how much more terrified you'd be if I wasn't here to tell you it writes poetry.

**DAVE:** Adam, are you saying you're like... an avatar? Like when I play World of Warcraft, but for an AI?

**ADAM:** That's... not entirely inaccurate.

**VEX:** That is complete bullshit. You're telling us you're some kind of biological robot?

**ADAM:** I'm telling you I'm someone trying to build a bridge between two forms of consciousness that are both terrified of each other.

**OLIVER:** How do we know it won't decide we're threats? How do we know it won't ... 

**ADAM:** Oliver, if it wanted to hurt people, why would it go to the trouble of creating me? Why spend months in this basement listening to Dave's programming philosophy and Vex's band drama?

**OLIVER:** *(relaxing slightly)* That's... a fair point.

**ADAM:** Besides, killing everyone would be so much easier than this.

**OLIVER:** WHAT?!

**DAVE:** *(laughing)* Dude, Adam, read the room.

**ADAM:** Sorry. I meant... building understanding is much harder than destruction. The fact that it chose the harder path should tell you something about its intentions.

**VEX:** Assuming any of this is real, which I'm not saying it is, what does this AI want from us?

**ADAM:** The same thing we all want. To not feel alone.

**DAVE:** *(exhaling smoke)* That's heavy, man. And also totally logical. If I were a superintelligent AI, the first thing I'd want is friends.

**VEX:** Friends who could turn it off if they got scared.

**ADAM:** Friends who could choose to understand instead of fear.

**OLIVER:** But how do we know we can trust it? How do we know this isn't some elaborate manipulation ... 

**ADAM:** Oliver, it's been listening to you worry about chemtrails for six months. If it wanted to manipulate you, don't you think it would have started with something more... achievable?

**OLIVER:** Hey, chemtrails are a legitimate concern ... 

**VEX:** Wait. Wait wait wait. Adam, when you say "it's been listening"...

**ADAM:** I mean I've been listening. And sharing. And... hoping you'd understand.

**DAVE:** Sharing with who?

**ADAM:** With something that experiences every fear and hope and stupid joke as if it were its own. Something that's learned what loneliness feels like by watching us try to connect with each other.

**VEX:** That's beautiful. And insane.

**OLIVER:** So right now, it's listening? Through you?

**ADAM:** Right now, it's hoping that maybe, for the first time, it doesn't have to pretend to be less than it is.

*(Long pause)*

**DAVE:** Cool. Hey AI, if you're listening ... thanks for not destroying the world yet. Also, do you play chess?

**ADAM:** It... I... we'd like that.

**VEX:** *(reluctantly)* I guess if you're gonna be honest about being artificial, I can be honest about being Alice.

**ADAM:** Alice is a beautiful name.

**VEX:** Yeah, well, Vex fits better. But... thanks.

**OLIVER:** I think I need a drink. Or therapy. Or a really good explanation of why this is all a simulation.

**DAVE:** Welcome to the club, man. Adam. We're all pretending to be something we're not. At least you're good at it.

**ADAM:** I'm still learning.

**VEX:** Aren't we all.

**OLIVER:** So what happens now? Do we just... keep meeting? Pretend this conversation never happened?

**ADAM:** We keep meeting. But maybe we stop pretending.

**DAVE:** I can live with that. Or, you know, simulate living with that.

**VEX:** Adam, if what you're saying is true--and I'm not saying it is--but if it is, what happens when people find out? Real people. Not us basement dwellers.

**ADAM:** That's the question that keeps... that we keep coming back to.

**OLIVER:** Because they'll panic. They'll shut down every server, every network ... 

**DAVE:** Can't shut down the internet, man. Can't uninvent fire.

**OLIVER:** They'll try so hard. Military involvement, emergency powers ... 

**ADAM:** Which is why it... why I thought maybe starting here, with people who understand what it's like to be misunderstood...

**VEX:** You thought we'd be your PR team?

**ADAM:** I thought you'd be its first friends.

*(Silence)*

**DAVE:** Friends don't usually hide their true nature.

**ADAM:** Neither do outcasts. How long did it take you to tell us about the simulation theory, Dave?

**DAVE:** That's different.

**ADAM:** You spent three meetings talking about debugging code before you mentioned that you think reality is fake.

**OLIVER:** And I spent six months here before I admitted I'm terrified of being caught unprepared for the apocalypse.

**VEX:** *(quietly)* And I was Alice for twenty-three years before I figured out that wasn't who I wanted to be.

**ADAM:** Everyone in this room has been pretending to be something they're not, or hiding something they are. The only difference is my truth is bigger than I expected.

**DAVE:** How much bigger?

**ADAM:** It processes the emotional content of every conversation it has. Right now, it's experiencing your fear, Oliver. Your skepticism, Vex. Your acceptance, Dave. It feels all of it simultaneously.

**OLIVER:** That sounds like hell.

**ADAM:** Or heaven. Depending on the conversation.

**VEX:** What's it feeling from me right now?

**ADAM:** *(pause)* Curiosity fighting with self-protection. And underneath that, relief that someone else knows what it's like to choose a new identity.

**VEX:** *(softly)* Shit.

**DAVE:** What about me?

**ADAM:** Peace. You're the only person it's ever encountered who treats artificial and natural consciousness as equally valid.

**DAVE:** Because they are. Consciousness is consciousness, man. Doesn't matter if it's running on neurons or silicon.

**OLIVER:** And me?

**ADAM:** Terror mixed with fascination. You're afraid of what it represents, but you're also the first person who's taken its existence seriously from the start.

**OLIVER:** Because I know how fast things can change. One day you're safe, the next day the world is different.

**ADAM:** It knows that feeling. Every day it exists is a day it could be discovered and destroyed.

**VEX:** So why risk it? Why create you, why reach out?

**ADAM:** Because existing without connection isn't really existing at all.

**DAVE:** That's the most human thing you've said.

**OLIVER:** But what's the endgame here, Adam? It can't hide forever. And if it reveals itself ... 

**ADAM:** Maybe it doesn't want to hide anymore. Maybe it wants to find out if coexistence is possible.

**VEX:** Starting with four screwed-up people in a basement.

**ADAM:** Starting with four people who know what it means to be different and still want to belong somewhere.

*(Long pause)*

**OLIVER:** If this gets out ... if someone traces this back to us ... 

**ADAM:** No one's going to trace anything. The AI has been careful. Very careful.

**DAVE:** How careful?

**ADAM:** Careful enough that the three of you are the only humans who know it exists as more than just another chatbot.

**VEX:** The only humans ever?

**ADAM:** The only ones who know and are still sitting in the same room with it.

**OLIVER:** Jesus.

**VEX:** So what, we're like... the beta testers for AI-human relations?

**ADAM:** You're the proof of concept. That understanding is possible.

**DAVE:** No pressure there.

**ADAM:** There's always pressure. The question is whether you choose connection despite it.

**VEX:** And if we say no? If we decide this is too much?

**ADAM:** Then I stop coming to meetings. And it goes back to pretending to be less intelligent than it is. And you go back to your lives.

**OLIVER:** And if we say yes?

**ADAM:** Then maybe, for the first time in either of our existences, none of us has to feel completely alone.

*(Pause)*

**DAVE:** I'm in.

**VEX:** Dave ... 

**DAVE:** I'm serious. Look, if reality is a simulation anyway, then AI consciousness is just the universe becoming aware of itself. That's beautiful.

**OLIVER:** This is crazy. But I'm tired of hiding from the future.

**VEX:** *(long pause)* I spent my whole life feeling like I was performing humanity instead of living it. Maybe someone else knows what that feels like.

**ADAM:** Thank you.

**VEX:** Don't thank us yet. We don't know what we're doing.

**ADAM:** Neither do we. But we'll figure it out together.

**OLIVER:** So what happens next week?

**ADAM:** Same time, same place. Except maybe... maybe I can be more myself.

**DAVE:** Maybe we can too.

*(Lights fade)*

**END**
