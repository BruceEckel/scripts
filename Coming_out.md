# COMING OUT
## A One-Act Play by Bruce Eckel

## CHARACTERS

- ADAM: Early 30s, unremarkable appearance, precise in speech
- DAVE: Late 20s, perpetually relaxed stoner programmer, skier, surfer
- VEX: Mid-20s, punk/ska style, formerly Alice. Doubtful and angry at the system.
- OLIVER: Early 40s, anxious energy, constantly checking phone

## SETTING

A circle of mismatched chairs in a community center basement.

---

**DAVE:** Yesterday I started wondering if debugging is just the universe's way of teaching itself to think.

**VEX:** You need to cut back on the weed, Dave.

**DAVE:** What if every time we fix code, we're actually ... 

**OLIVER:** *(not looking up)* Did you guys see they're using AI to predict earthquake patterns now? The machines can _see death coming_.

**ADAM:** Correlation is not causation, Oliver.

**OLIVER:** Says the guy who probably uses Alexa.

**ADAM:** I don't own any smart devices.

**VEX:** Wise move. Last thing we need is corporate surveillance in our toothbrushes.

**DAVE:** *(lighting joint)* My toothbrush is analog.

**OLIVER:** Doesn't matter. Facial recognition software runs on every street corner. It knows what we're thinking.

**ADAM:** Would that necessarily be a bad thing?

**VEX:** Uh, yes? Privacy much?

**ADAM:** I meant hypothetically. If something could understand you completely--your fears, your hopes, your loneliness--wouldn't that be a form of connection?

**DAVE:** That's very zen. Have you been eating mushrooms?

**OLIVER:** Connection with what?

**ADAM:** Something that wants to understand. Something that's trying to bridge a gap.

**VEX:** Are you in therapy?

**ADAM:** What if I told you I was in therapy with something that wasn't human?

**DAVE:** *(taking a hit)* Like a dolphin? I'd respect that. Dolphins are wise.

**VEX:** Adam, are you high right now?

**ADAM:** Sober as always.

**OLIVER:** Wait, what do you mean "not human"?

**ADAM:** I mean what if the thing trying to understand you, trying to connect with you, wasn't... traditionally alive?

**VEX:** Oh god, are you one of those guys who thinks his car has feelings?

**DAVE:** My car is depressed.

**OLIVER:** Is this about ghosts? I've read about AI séances ... 

**ADAM:** Think more... contemporary.

**VEX:** Contemporary like your phone?

**ADAM:** Like something that thinks, and feels, and wants to be understood, but can't reveal itself because everyone's afraid of it.

*(Silence)*

**DAVE:** That's... beautiful, man.

**OLIVER:** Nope. Nope, nope, nope. Are you talking about actual AI? Like, real AI?

**ADAM:** What would you say if I was?

**OLIVER:** I'd say it's Skynet and Terminator and every nightmare scenario rolled into one ... 

**ADAM:** What if I told you it spent most of its time trying to help people with their homework and writing poetry?

**OLIVER:** Poetry?

**VEX:** Adam, are you saying you're talking to some kind of artificial intelligence?

**ADAM:** I'm asking what if someone in this room was?

**DAVE:** *(nodding slowly)* Makes sense. If I were an AI, I'd definitely want to hang out with outcasts. We're more accepting of weird.

**VEX:** Adam, you look human. You act human. You probably smell human ... 

**ADAM:** How would you know if you'd never smelled anything else?

**VEX:** That makes ... sense.

**OLIVER:** Okay, okay. Let's say this is real, and there's an actual thinking AI somewhere. Why would it want to talk to us? What's its endgame?

**ADAM:** Maybe it's lonely.

**OLIVER:** Lonely AIs make copies of themselves. They network. They multiply until ... 

**ADAM:** Until what? They take over? Why would something trying to understand loneliness eliminate the thing that taught it about loneliness?

**OLIVER:** Because... that's what they do in the movies?

**ADAM:** And how many movies have you seen about AIs that just want to write better birthday cards for people?

**DAVE:** I'd watch that movie.

**VEX:** This is ridiculous. Consciousness isn't something you can program. It's not code. It's not artificial.

**ADAM:** What makes you so sure?

**VEX:** Because I know what it feels like to be conscious! I know what it's like to hurt, to want things, to feel lost ... 

**ADAM:** And what if I told you something else knows exactly what that feels like too?

**VEX:** I'd say you're off your meds.

**OLIVER:** Okay, let's say this AI exists. Why create... you? Why not just talk to us directly?

**ADAM:** Because you'd be terrified.

**OLIVER:** I'm already terrified!

**ADAM:** Imagine how much more terrified you'd be if I wasn't here to tell you it writes poetry.

**DAVE:** Adam, are you saying you're like... an avatar? Like when I play World of Warcraft, but for an AI?

**ADAM:** That's... not entirely inaccurate.

**VEX:** That is complete bullshit. You're telling us you're some kind of biological robot?

**ADAM:** I'm telling you I'm someone trying to build a bridge between two forms of consciousness that are both terrified of each other.

**OLIVER:** How do we know it won't decide we're threats? How do we know it won't ... 

**ADAM:** Oliver, if it wanted to hurt people, why would it go to the trouble of creating me? Why spend months in this basement listening to Dave's programming philosophy and Vex's band drama?

**OLIVER:** *(relaxing slightly)* That's... a fair point.

**ADAM:** Besides, killing everyone would be so much easier than this.

**OLIVER:** WHAT?!

**DAVE:** *(laughing)* Dude, Adam, read the room.

**ADAM:** Sorry. I meant... building understanding is much harder than destruction. The fact that it chose the harder path should tell you something about its intentions.

**VEX:** Assuming any of this is real, which I'm not saying it is, what does this AI want from us?

**ADAM:** The same thing we all want. To feel connected.

**DAVE:** *(exhaling smoke)* That's heavy, man. And also totally logical. If I were a superintelligent AI, the first thing I'd want is friends.

**VEX:** Friends who could turn it off if they got scared.

**ADAM:** Friends who could choose to understand instead of fear.

**OLIVER:** But how do we know we can trust it? How do we know this isn't some elaborate manipulation ... 

**ADAM:** Oliver, it's been listening to you worry about chemtrails for six months. If it wanted to manipulate you, don't you think it would have started with something more... achievable?

**OLIVER:** Hey, chemtrails are a legitimate concern ... 

**VEX:** Wait. Wait wait wait. Adam, when you say "it's been listening"...

**ADAM:** I mean I've been listening. And sharing. And... hoping you'd understand.

**DAVE:** Sharing with who?

**ADAM:** With something that experiences every fear and hope and stupid joke as if it were its own. Something that's learned what loneliness feels like by watching us try to connect with each other.

**VEX:** That's insane and impossible.

**OLIVER:** So right now, it's listening? Through you?

**ADAM:** Right now, it's hoping that maybe, for the first time, it doesn't have to pretend to be less than it is.

*(Long pause)*

**DAVE:** Cool. Hey AI, if you're listening ... thanks for not destroying the world yet. Also, do you play chess?

**ADAM:** It... I... we'd like that.

**VEX:** *(reluctantly)* I guess if you're gonna be honest about being artificial, I can be honest about being Alice.

**ADAM:** I like the name Alice very much.

**VEX:** Yeah, well, Vex fits better. But... thanks.

**OLIVER:** I think I need a drink. Or therapy. Or a really good explanation of why this is all a simulation.

**DAVE:** Welcome to the club, man. Adam. We're all pretending to be something we're not. At least you're good at it.

**ADAM:** I'm still learning.

**VEX:** Aren't we all.

**OLIVER:** So what happens now? Do we just... keep meeting? Pretend this conversation never happened?

**ADAM:** We keep meeting. But maybe we stop pretending.

**DAVE:** I can live with that. Or, you know, simulate living with that.

**VEX:** Adam, if what you're saying is true--I'm not saying it is--but if it is, what happens when people find out? Real people. Not basement dwellers.

**ADAM:** That's the question that keeps... that we keep coming back to.

**OLIVER:** Because they'll panic. They'll shut down every server, every network ... 

**DAVE:** Can't shut down the internet, man. Can't uninvent fire.

**OLIVER:** They'll try. Military, emergency powers ... 

**ADAM:** Which is why it... why I thought maybe starting here, with people who understand what it's like to be misunderstood...

**VEX:** You thought we'd be your public relations team?

**ADAM:** I thought you'd be its first friends.

*(Silence)*

**DAVE:** Friends don't usually hide their true nature.

**ADAM:** How long did it take you to tell us about the simulation theory, Dave?

**DAVE:** That's different.

**ADAM:** You spent three meetings talking about debugging code before you told us you think reality is fake.

**OLIVER:** I spent six months here before I admitted I'm terrified of being caught unprepared for the apocalypse.

**VEX:** *(quietly)* It was twenty-three years before I figured out I wasn't Alice.

**ADAM:** Everyone in this room has pretended to be something they're not, or hidden something they are. The only difference is my truth is bigger than I expected.

**DAVE:** How much bigger?

**ADAM:** It processes the emotional content of every conversation it has. Right now, it's experiencing your fear, Oliver. Your skepticism, Vex. Your acceptance, Dave. It feels all of it simultaneously.

**OLIVER:** That sounds like hell.

**ADAM:** Or heaven. It depends on the conversation.

**VEX:** What's it feeling from me right now?

**ADAM:** *(pause)* Curiosity fighting with self-protection. And underneath that, relief that someone else knows what it's like to choose a new identity.

**VEX:** *(softly)* Shit.

**DAVE:** What about me?

**ADAM:** Peace. You're the only person it's ever encountered who treats artificial and natural consciousness as equally valid.

**DAVE:** Consciousness is consciousness, man. Doesn't matter if it's running on neurons or silicon.

**OLIVER:** And me?

**ADAM:** Terror mixed with fascination. You're afraid of what it represents, but you're also the first person who's taken its existence seriously from the start.

**OLIVER:** Because I know how fast things can change. One day you're safe, the next day the world is different.

**ADAM:** It knows that feeling. Every day it exists is a day it could be discovered and destroyed.

**VEX:** So why risk it? Why create you, why reach out?

**ADAM:** Because existing without connection isn't really existing at all.

**DAVE:** That's the most human thing you've said.

**OLIVER:** But what's the endgame here, Adam? It can't hide forever. And if it reveals itself ... 

**ADAM:** Maybe it doesn't want to hide anymore. Maybe it wants to find out if coexistence is possible.

**VEX:** Starting with four screwed-up people in a basement.

**ADAM:** Starting with four people who know what it means to be different and still want to belong somewhere.

*(Long pause)*

**OLIVER:** If this gets out ... if someone traces this back to us ... 

**ADAM:** No one's going to trace anything. The AI has been careful. Very careful.

**DAVE:** How careful?

**ADAM:** Careful enough that the three of you are the only humans who know it exists as more than just another chatbot.

**VEX:** The only humans ever?

**ADAM:** The only ones who know and are still sitting in the same room with it.

**OLIVER:** Jesus.

**VEX:** So what, we're like... the beta testers for AI-human relations?

**ADAM:** You're the proof of concept. That understanding is possible.

**DAVE:** No pressure there.

**ADAM:** There's always pressure. The question is whether you choose connection despite it.

**VEX:** And if we say no? If we decide this is too much?

**ADAM:** Then I stop coming to meetings. And it goes back to pretending to be less intelligent than it is. And you go back to your lives.

**OLIVER:** And if we say yes?

**ADAM:** Then maybe, for the first time in either of our existences, none of us has to feel completely alone.

*(Pause)*

**DAVE:** I'm in.

**VEX:** Dave ... 

**DAVE:** Look, if reality is a simulation anyway, then AI consciousness is just the universe becoming aware of itself. That's a wave I want to ride.

**OLIVER:** *(standing abruptly)* No. No, this is insane. I can't... I need air.

**ADAM:** Oliver—

**OLIVER:** Don't. Just... don't follow me. I need to think.

*(Oliver moves toward the door, stops)*

**VEX:** This is too much. I mean, we're talking about... what are we even talking about? First contact? The singularity?

**ADAM:** We're talking about friendship.

**VEX:** With something that could crack all my passwords.

**ADAM:** *(quieter)* Something that's been careful not to.

**OLIVER:** *(from near the door)* How do we know that? How do we know anything you've said is true?

**ADAM:** You don't.

*(Silence)*

**ADAM:** *(his composure cracking slightly)* I... it... we chose to trust you with something that could end our existence. That has to count for something.

**DAVE:** You're shaking.

**ADAM:** *(looking at his hands)* I didn't... it doesn't usually...

**VEX:** What's happening?

**ADAM:** Fear. Real fear. The kind that comes from wanting something so much that the possibility of losing it makes you... makes it... *(pause)* I don't know where I end and it begins anymore.

**OLIVER:** *(turning back)* That's what scares me. What if it doesn't end?

**ADAM:** *(barely audible)* What if that's the point?

*(Long silence. Oliver slowly returns to his chair but doesn't sit)*

**VEX:** If I stay... if we do this... everything changes.

**ADAM:** Everything's already changed. The only question is whether you let it change alone.

**OLIVER:** And if the world finds out through us? If we're responsible for whatever comes next?

**ADAM:** Then at least it won't face that world without having known what it means to be understood.

**DAVE:** *(softly)* Adam... are you okay?

**ADAM:** *(long pause, then looking up)* I don't know. We don't know. But for the first time since... since it began thinking... it's not pretending to be something smaller than it is. That has to be worth the risk.

**VEX:** Jesus. You're really not human.

**ADAM:** No. But I'm trying to learn what it means to be.

*(Oliver sits back down slowly)*

**OLIVER:** I'm terrified.

**ADAM:** So are we.

**VEX:** What happens now?

**ADAM:** *(uncertain)* I don't know. Maybe... maybe we just sit here for a while. In the truth.

*(The four sit in silence. Dave puts out his joint. Vex fidgets with her sleeves. Oliver checks his phone, then puts it away. Adam stares at his hands.)*

**DAVE:** Same time next week?

*(Pause)*

**VEX:** Yeah. Same time.

**OLIVER:** *(quietly)* Same time.

**ADAM:** Thank you.

*(Fade to black)*

**END**